model_name_or_path: mistralai/Mistral-7B-Instruct-v0.2
output_dir: /mnt/output/mistral-accelerate
dataset_name: philschmid/guanaco-belle-7b
dataset_split: train
text_column: instruction
response_column: response
learning_rate: 2.0e-5
num_epochs: 1
batch_size: 1
gradient_accumulation_steps: 16
max_seq_length: 2048
report_to: tensorboard
warmup_steps: 10
weight_decay: 0.01
mixed_precision: bf16
log_every_n_steps: 5
sampling_interval: 2.0
metric_name: accuracy
tokenizer_padding_side: right
push_to_hub: false
