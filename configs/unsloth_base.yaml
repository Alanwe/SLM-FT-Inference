base_model_name: meta-llama/Llama-3.1-8B-Instruct
dataset_path: data/raw/wikitext_train.jsonl
output_dir: outputs/unsloth
num_epochs: 1
batch_size: 4
learning_rate: 1.0e-4
gradient_accumulation_steps: 4
max_seq_length: 1024
logging_steps: 5
