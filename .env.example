# Azure credentials
AZURE_SUBSCRIPTION_ID=
AZURE_TENANT_ID=
AZURE_CLIENT_ID=
AZURE_CLIENT_SECRET=
AZURE_RESOURCE_GROUP=
AZURE_REGION=

# Storage and logging
AZURE_STORAGE_ACCOUNT=
AZURE_CONTAINER=
LOGGING_MLFLOW_URI=
PROMETHEUS_GATEWAY=

# Hugging Face & datasets
HF_TOKEN=
DATASET_NAME=philschmid/guanaco-belle-7b
DATASET_SPLIT=train
DATASET_TEXT_COLUMN=instruction
DATASET_RESPONSE_COLUMN=response
OUTPUT_DIR=/mnt/output
MODEL_NAME_OR_PATH=mistralai/Mistral-7B-Instruct-v0.2

# Training hyperparameters (overridable via CLI/config)
LEARNING_RATE=2e-5
NUM_EPOCHS=1
BATCH_SIZE=1
GRADIENT_ACCUMULATION_STEPS=16
MAX_SEQ_LENGTH=2048

# Inference defaults
INFERENCE_PROMPT_FILE=prompts/sample_prompts.jsonl
INFERENCE_CONCURRENCY=8

# Monitoring
METRICS_SAMPLING_INTERVAL=2.0
